{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load SEED Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a29db2a0b135a13b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load RAW EEG",
   "id": "24699bd8dcadd704"
  },
  {
   "cell_type": "code",
   "source": [
    "from dataset_processing.seed_dataset_loader import SeedDatasetLoader\n",
    "\n",
    "sampling_frequency = 200  # 200 Hz\n",
    "\n",
    "_loader = SeedDatasetLoader(fs=sampling_frequency)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f28dcf2b965f8640",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "labels = _loader.get_labels()\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca4d22bed4a15e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "channel_order = _loader.get_channel_order()\n",
    "channel_order"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8b0f267cb93aacf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_eeg_data_df = _loader.get_eeg_data_df()",
   "id": "71c84272baaf52fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "_loader.plot_random_eeg()",
   "metadata": {
    "collapsed": false
   },
   "id": "e227135b42d3ad7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "del _loader",
   "id": "af4511eb8ab884d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Data Augmentation",
   "metadata": {
    "collapsed": false
   },
   "id": "3405db51e6dde34e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataset_processing.eeg_augmentation import EEGAugmentation\n",
    "\n",
    "_augmentor = EEGAugmentation(_eeg_data_df)\n",
    "_augmented_df = _augmentor.augment_data()\n",
    "del _augmentor, _eeg_data_df"
   ],
   "id": "cb020fa64271167f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre-Training",
   "id": "ad9af7bc72ac020d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset Loader",
   "id": "116d350633bb880f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset_processing.eeg_dataset import EEGDataset\n",
    "\n",
    "# From the paper\n",
    "pretraining_batch_size = 256\n",
    "\n",
    "_dataset = EEGDataset(_augmented_df)\n",
    "data_loader = DataLoader(_dataset, batch_size=pretraining_batch_size, shuffle=True)\n",
    "del _augmented_df, _dataset"
   ],
   "id": "ced1c49f14fc7150"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Do the pre-training",
   "id": "bb188c0dbcb163af"
  },
  {
   "cell_type": "code",
   "source": [
    "from model.pre_training.do_pre_training import PreTraining\n",
    "\n",
    "pretraining = PreTraining(\n",
    "    data_loader=data_loader,\n",
    "    sampling_frequency=sampling_frequency,\n",
    "    pretraining_model_save_dir=\"model_params/pretraining\",\n",
    "    epochs=10,\n",
    ")\n",
    "pretraining.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ebf017b23d22c9f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-Tuning",
   "id": "d52e28a9f9218d03"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Dataset Loader",
   "id": "9ee25fc044cb4938"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from torch.utils.data import DataLoader\n",
    "# from dataset_processing.eeg_dataset import EEGDataset\n",
    "# \n",
    "# # From the paper\n",
    "# pretraining_batch_size = 256\n",
    "# \n",
    "# _dataset = EEGDataset(_augmented_df)\n",
    "# data_loader = DataLoader(_dataset, batch_size=pretraining_batch_size, shuffle=True)\n",
    "# del _augmented_df, _dataset"
   ],
   "id": "ee9b7dd3e7b33359"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Do the fine-tuning",
   "id": "4b86e0b0a5e34884"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# from model.fine_tuning.do_fine_tuning import FineTuning\n",
    "# \n",
    "# finetuning = FineTuning(\n",
    "#     data_loader=data_loader,\n",
    "#     sampling_frequency=sampling_frequency,\n",
    "#     finetuning_model_save_dir=\"model_params/finetuning\",\n",
    "#     epochs=10,\n",
    "# )\n",
    "# finetuning.train()"
   ],
   "id": "4eb9f66758227bd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ideas",
   "id": "8099d554347b0eab"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do a correlation matrix between the channels of the EEG signals.\n",
    "Then when doing the joint whatever model, use the \"distances\" between the channels (like the hamming distance but not really), as a \"weight\" for training the joining etc.\n",
    "\n",
    "Or maybe just output something that could show each channel's contribution towards the final emotion prediction."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dddb3704166f6cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
