{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Load SEED Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a29db2a0b135a13b"
  },
  {
   "cell_type": "code",
   "source": [
    "from utils.seed_dataset_loader import SeedDatasetLoader\n",
    "\n",
    "loader = SeedDatasetLoader()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f28dcf2b965f8640",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "labels = loader.get_labels()\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca4d22bed4a15e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "channel_order = loader.get_channel_order()\n",
    "channel_order"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8b0f267cb93aacf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "eeg_data_df = loader.get_eeg_data_df()",
   "id": "71c84272baaf52fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "loader.plot_random_eeg()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e227135b42d3ad7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "del loader",
   "id": "af4511eb8ab884d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Data Augmentation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3405db51e6dde34e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from utils.eeg_augmentation import EEGAugmentation"
   ],
   "id": "cb020fa64271167f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "augmentor = EEGAugmentation(eeg_data_df)\n",
    "augmented_df = augmentor.augment_data()"
   ],
   "id": "16f58c0cc091a941",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "augmented_df.iloc[0]",
   "id": "9f258d36210c0426",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "4e2f0ab740c3341d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "def nt_xent_loss(z, z_augmented, temperature=0.05):\n",
    "    \"\"\"\n",
    "    Calculates the NT-Xent loss for a batch of embeddings and their augmented versions, where the positive pair\n",
    "    consists of each embedding and its augmentation, and negative pairs are computed between the embedding and all\n",
    "    other non-augmented embeddings in the batch.\n",
    "    \n",
    "    Parameters:\n",
    "    - z (torch.Tensor): Embeddings from the original EEG signals.\n",
    "    - z_augmented (torch.Tensor): Corresponding embeddings from the augmented EEG signals.\n",
    "    - temperature (float): Temperature scaling factor for the softmax.\n",
    "    \n",
    "    Returns:\n",
    "    - torch.Tensor: The average NT-Xent loss for the batch.\n",
    "    \"\"\"\n",
    "    device = z.device\n",
    "    batch_size = z.size(0)\n",
    "\n",
    "    # Normalize the embeddings to use cosine similarity\n",
    "    z = F.normalize(z, p=2, dim=1).to(device)\n",
    "    z_augmented = F.normalize(z_augmented, p=2, dim=1).to(device)\n",
    "\n",
    "    # Calculate the cosine similarity between each original and its augmented version (positive pairs)\n",
    "    # Already normalized, so no need to divide by anything\n",
    "    positive_sim = torch.sum(z * z_augmented, dim=1) / temperature\n",
    "\n",
    "    # Calculate cosine similarity between each original and all other originals (for negatives)\n",
    "    negative_sim_matrix = torch.mm(z, z.t()) / temperature\n",
    "    # Mask out self-similarities (diagonal elements)\n",
    "    mask = torch.eye(batch_size, device=device)\n",
    "    negative_sim_matrix = negative_sim_matrix.masked_fill(mask == 1, float('-inf'))\n",
    "\n",
    "    # Use log-sum-exp trick to calculate the denominator of the softmax function\n",
    "    # Ref: https://gregorygundersen.com/blog/2020/02/09/log-sum-exp/\n",
    "    # max_negative_sim = torch.max(negative_sim_matrix, dim=1, keepdim=True)[0]\n",
    "    # exp_negative_sim = torch.exp(negative_sim_matrix - max_negative_sim)\n",
    "    # sum_exp_negative_sim = torch.sum(exp_negative_sim, dim=1, keepdim=True)\n",
    "    # logsumexp_negatives = torch.log(sum_exp_negative_sim + 1e-6) + max_negative_sim.squeeze()\n",
    "    logsumexp_negatives = torch.logsumexp(negative_sim_matrix, dim=1)\n",
    "\n",
    "    # Calculate log probabilities for the positives in relation to the log of the sum of exponentiated negative similarities\n",
    "    log_prob = positive_sim - logsumexp_negatives\n",
    "\n",
    "    # Mean loss across all samples\n",
    "    loss = -torch.mean(log_prob)\n",
    "\n",
    "    return loss"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd4175d590279b0c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "18f58fe7d5fb9e23",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "eeg_augmentation = EEGAugmentation(None)",
   "metadata": {
    "collapsed": false
   },
   "id": "7838dc54f6923b56",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Dummy EEG data\n",
    "torch.manual_seed(seed=1)\n",
    "x = torch.randn(256, 128)  # 256 samples, 128 features per sample\n",
    "\n",
    "# Augment the time-domain data\n",
    "xe = eeg_augmentation._time_gaussian_noise(x)\n",
    "\n",
    "# Simulate encoding process to generate embeddings\n",
    "time_encoder = torch.nn.Linear(128, 64)  # Dummy encoder\n",
    "h = time_encoder(x)\n",
    "he = time_encoder(xe)\n",
    "\n",
    "# Compute the loss\n",
    "loss_time = nt_xent_loss(h, he)\n",
    "print(f\"Time Domain - Contrastive Loss: {loss_time.item()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d3b418678187f73",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "# Assume x is the input EEG signal\n",
    "torch.manual_seed(seed=1)\n",
    "x = torch.randn(256, 128)  # Dummy EEG data, 256 samples, 128 features per sample\n",
    "\n",
    "# Convert to frequency domain\n",
    "xF = eeg_augmentation._freq_fourier_transform(x)\n",
    "\n",
    "# Apply spectral perturbation\n",
    "xeF = eeg_augmentation._freq_spectral_perturbation(xF)\n",
    "\n",
    "# Let's assume you have an encoder for frequency data\n",
    "frequency_encoder = torch.nn.Linear(128, 64)  # Dummy encoder for frequency domain\n",
    "\n",
    "# Generate embeddings\n",
    "hF = frequency_encoder(xF)\n",
    "heF = frequency_encoder(xeF)\n",
    "\n",
    "# Compute the contrastive loss\n",
    "loss_frequency = nt_xent_loss(hF, heF)\n",
    "print(f\"Frequency Domain - Contrastive Loss: {loss_frequency.item()}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3d6e9ae795b9605b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "dae047e098f4c9f4",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Do a correlation matrix between the channels of the EEG signals.\n",
    "Then when doing the joint whatever model, use the \"distances\" between the channels (like the hamming distance but not really), as a \"weight\" for training the joining etc."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1dddb3704166f6cd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
