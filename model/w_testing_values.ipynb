{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Try to use these to fix outputs issue:\n",
    "\n",
    "https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "https://notebook.community/lifeinoppo/littlefishlet-scode/RES/REF/python_sourcecode/ipython-master/examples/IPython%20Kernel/Capturing%20Output"
   ],
   "id": "206fd0459d5c59b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load SEED Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a29db2a0b135a13b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Load RAW EEG",
   "id": "24699bd8dcadd704"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataset_processing.seed_dataset_loader import SeedDatasetLoader\n",
    "\n",
    "sampling_frequency = 200  # 200 Hz\n",
    "\n",
    "_loader = SeedDatasetLoader(fs=sampling_frequency)"
   ],
   "id": "f28dcf2b965f8640",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "labels = _loader.get_labels()\n",
    "labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ca4d22bed4a15e46",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "channel_order = _loader.get_channel_order()\n",
    "channel_order"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f8b0f267cb93aacf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "_eeg_data_df = _loader.get_eeg_data_df()",
   "id": "71c84272baaf52fc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "_loader.plot_random_eeg()",
   "metadata": {
    "collapsed": false
   },
   "id": "e227135b42d3ad7c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "del _loader",
   "id": "af4511eb8ab884d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "### Data Augmentation",
   "metadata": {
    "collapsed": false
   },
   "id": "3405db51e6dde34e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from dataset_processing.eeg_augmentation import EEGAugmentation\n",
    "\n",
    "_augmentor = EEGAugmentation(_eeg_data_df)\n",
    "_augmented_df = _augmentor.augment_data()\n",
    "del _augmentor, _eeg_data_df"
   ],
   "id": "cb020fa64271167f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Pre-Training Tests",
   "id": "ad9af7bc72ac020d"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Preparations",
   "id": "9540a03699523a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from dataset_processing.eeg_dataset import EEGDataset\n",
    "from model.pre_training.do_pre_training import PreTraining\n",
    "\n",
    "# From the paper\n",
    "pretraining_batch_size = 256"
   ],
   "id": "c370fe3af6a91b1a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_dataset = EEGDataset(_augmented_df)\n",
    "del _augmented_df"
   ],
   "id": "395ce4c16b501f4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from utils.misc import sort_dict_by_values\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "\n",
    "# TODO: Add in bachelor thesis how `num_workers` was chosen with code below\n",
    "\n",
    "# Custom cleanup function, useful when using the dataloader too much,\n",
    "# as it's bugged and needs manual cleaning (because of Jupyter Notebook)\n",
    "def cleanup_data_loader(loader):\n",
    "    # noinspection PyProtectedMember\n",
    "    if loader._iterator is not None:\n",
    "        # noinspection PyProtectedMember\n",
    "        loader._iterator._shutdown_workers()\n",
    "\n",
    "\n",
    "def pretraining_testing(\n",
    "        _testing_epochs,  # Epochs\n",
    "        _num_workers, _prefetch_factor,  #  From DataLoader\n",
    "        _scheduler_patience, _early_stopping_patience  # From PreTraining\n",
    "):\n",
    "    print(\n",
    "        f\"Testing Pre-Training for {_testing_epochs} epochs (\"\n",
    "        f\"{_num_workers} workers loading the dataset, \"\n",
    "        f\"scheduler_patience: {_scheduler_patience}, \"\n",
    "        f\"early_stopping_patience: {_early_stopping_patience}).\"\n",
    "    )\n",
    "\n",
    "    _data_loader = DataLoader(\n",
    "        _dataset,\n",
    "        batch_size=pretraining_batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=True,\n",
    "\n",
    "        persistent_workers=_num_workers > 0,\n",
    "        num_workers=_num_workers,\n",
    "        prefetch_factor=_prefetch_factor,  # Default: 2 for `num_workers` > 0\n",
    "    )\n",
    "\n",
    "    _pretraining = PreTraining(\n",
    "        data_loader=_data_loader,\n",
    "        sampling_frequency=sampling_frequency,\n",
    "        scheduler_patience=_scheduler_patience,  # 50 default\n",
    "        early_stopping_patience=_early_stopping_patience,\n",
    "        epochs=_testing_epochs,\n",
    "\n",
    "        pretraining_model_save_dir=None,\n",
    "        log_dir=None,\n",
    "    )\n",
    "    _pretraining.train(update_after_every_epoch=False)\n",
    "\n",
    "    cleanup_data_loader(_data_loader)\n",
    "    del _data_loader\n",
    "\n",
    "    return dict(\n",
    "        last_epoch_loss=_pretraining.last_epoch_loss,\n",
    "        overall_elapsed_time=_pretraining.overall_elapsed_time,\n",
    "    )"
   ],
   "id": "914db3565818727b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test `num_workers` and `prefetch_factor` for DataLoader",
   "id": "bad25ba49b39438d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_data_loader_test_epochs = 25\n",
    "_num_workers_values = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "_prefetch_factor_values = [1, 2, 4, 8]\n",
    "\n",
    "data_loader_test_times_dict = dict()\n",
    "\n",
    "print(\n",
    "    f\"Starting to test `num_workers` (from {_num_workers_values}) and \"\n",
    "    f\"`prefetch_factor` (from {_prefetch_factor_values}) for DataLoader, \"\n",
    "    f\"while pre-training for {_data_loader_test_epochs} epochs\"\n",
    ")\n",
    "for num_workers in _num_workers_values:\n",
    "    for prefetch_factor in _prefetch_factor_values:\n",
    "        res = pretraining_testing(\n",
    "            _testing_epochs=_data_loader_test_epochs,\n",
    "\n",
    "            _num_workers=num_workers,\n",
    "            _prefetch_factor=prefetch_factor,\n",
    "\n",
    "            # Disable the patience\n",
    "            _scheduler_patience=_data_loader_test_epochs,\n",
    "            _early_stopping_patience=_data_loader_test_epochs,\n",
    "        )\n",
    "        data_loader_test_times_dict[(num_workers, prefetch_factor)] = res[\"overall_elapsed_time\"]\n",
    "\n",
    "data_loader_test_times_dict = sort_dict_by_values(  # Wort by lowest `time` first\n",
    "    data_loader_test_times_dict,\n",
    "    reverse=False,\n",
    ")\n",
    "\n",
    "print()\n",
    "for (num_workers, prefetch_factor), overall_elapsed_time in data_loader_test_times_dict.items():\n",
    "    formatted_time = str(timedelta(seconds=overall_elapsed_time))[:-3]\n",
    "    print(\n",
    "        f\"For {{num_workers: {num_workers}, \"\n",
    "        f\"prefetch_factor: {prefetch_factor}}} -> \"\n",
    "        f\"Time Taken: {formatted_time}\"\n",
    "    )\n",
    "print()\n",
    "\n",
    "best_num_workers, best_prefetch_factor = list(data_loader_test_times_dict.keys())[0]\n",
    "print(\n",
    "    f\"Best results -> \"\n",
    "    f\"(`best_num_workers`: {best_num_workers}, \"\n",
    "    f\"`best_prefetch_factor`: {best_prefetch_factor})\"\n",
    ")"
   ],
   "id": "7e71615007eeb5e3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "##### Results for choosing best value for `num_workers` (HH:MM:SS.milliseconds)\n",
    "Time/epoch with `num_workers = 0`: `0:18:18.900`\n",
    "\n",
    "Time/epoch with `num_workers = 1`: `0:08:41.793`\n",
    "\n",
    "Time/epoch with `num_workers = 2`: `0:06:42.313`\n",
    "\n",
    "Time/epoch with `num_workers = 3`: `0:06:36.799`\n",
    "\n",
    "Time/epoch with `num_workers = 4`: `0:06:52.586`\n",
    "\n",
    "Time/epoch with `num_workers = 8`: `0:06:44.983`"
   ],
   "id": "33f4bcdd09bb3d40"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Test `scheduler_patience` and `early_stopping_patience` for DataLoader",
   "id": "c1dcf44d6a440a20"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "_pre_training_test_epochs = 1000\n",
    "_scheduler_patience_values = [10, 25, 50, 75, 100]\n",
    "_early_stopping_patience_values = [10, 25, 50, 75, 100]\n",
    "\n",
    "pre_training_test_times_dict = dict()\n",
    "\n",
    "print(\n",
    "    f\"Starting to test `scheduler_patience` (from {_scheduler_patience_values}) and \"\n",
    "    f\"`early_stopping_patience` (from {_early_stopping_patience_values}) for PreTraining, \"\n",
    "    f\"while pre-training for {_pre_training_test_epochs} epochs\"\n",
    ")\n",
    "print(\n",
    "    f\"Will use previous best results -> \"\n",
    "    f\"(`best_num_workers`: {best_num_workers}, \"\n",
    "    f\"`best_prefetch_factor`: {best_prefetch_factor})\"\n",
    ")\n",
    "for scheduler_patience in _scheduler_patience_values:\n",
    "    for early_stopping_patience in _early_stopping_patience_values:\n",
    "        res = pretraining_testing(\n",
    "            _testing_epochs=_pre_training_test_epochs,\n",
    "\n",
    "            _num_workers=best_num_workers,\n",
    "            _prefetch_factor=best_prefetch_factor,\n",
    "\n",
    "            # Disable the patience\n",
    "            _scheduler_patience=scheduler_patience,\n",
    "            _early_stopping_patience=early_stopping_patience,\n",
    "        )\n",
    "        pre_training_test_times_dict[(scheduler_patience, early_stopping_patience)] = res[\"last_epoch_loss\"]\n",
    "\n",
    "pre_training_test_times_dict = sort_dict_by_values(  # Wort by lowest `loss` first\n",
    "    pre_training_test_times_dict,\n",
    "    reverse=False,\n",
    ")\n",
    "\n",
    "print()\n",
    "for (scheduler_patience, early_stopping_patience), last_epoch_loss in data_loader_test_times_dict.items():\n",
    "    print(\n",
    "        f\"For {{scheduler_patience: {scheduler_patience}, \"\n",
    "        f\"early_stopping_patience: {early_stopping_patience}}} -> \"\n",
    "        f\"Final Loss: {last_epoch_loss:.4f}\"\n",
    "    )\n",
    "print()\n",
    "\n",
    "best_scheduler_patience, best_pretraining_testing = list(pre_training_test_times_dict.keys())[0]\n",
    "print(\n",
    "    f\"Best results -> \"\n",
    "    f\"(`best_scheduler_patience`: {best_scheduler_patience}, \"\n",
    "    f\"`best_pretraining_testing`: {best_pretraining_testing})\"\n",
    ")"
   ],
   "id": "1cfd0859dba8d07b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Fine-Tuning Tests",
   "id": "d52e28a9f9218d03"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a71288473bfdfa53"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
